# Pika port
port : 9221
# Thread Number
# thread-num : 1
thread-num : <THREAD-NUM>
# Thread Pool Size
# thread-pool-size : 12
thread-pool-size : <THREAD-POOL-SIZE>
# Sync Thread Number
# sync-thread-num : 6
sync-thread-num : <SYNC-THREAD-NUM>
# Pika log path
# log-path : ./log/
log-path : <LOG-PATH>
# Pika db path
# db-path : ./db/
db-path : <DB-PATH>
# Pika write-buffer-size
# write-buffer-size : 268435456
write-buffer-size : <WRITE-BUFFER-SIZE>
# size of one block in arena memory allocation.
# If <= 0, a proper value is automatically calculated
# (usually 1/8 of writer-buffer-size, rounded up to a multiple of 4KB)
# arena-block-size :
arena-block-size : <ARENA-BLOCK-SIZE>
# Pika timeout
# timeout : 60
timeout : <TIMEOUT>
# Requirepass
# requirepass :
requirepass : <REQUIREPASS>
# Masterauth
# masterauth :
masterauth : <MASTERAUTH>
# Userpass
# userpass : 
userpass : <USERPASS>
# User Blacklist
# userblacklist :
userblacklist : <USERBLACKLIST>
# if this option is set to 'classic', that means pika support multiple DB, in
# this mode, option databases enable
# if this option is set to 'sharding', that means pika support multiple Table, you
# can specify slot num for each table, in this mode, option default-slot-num enable
# Pika instance mode [classic | sharding]
# instance-mode : classic
instance-mode : <INSTANCE-MODE>
# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT <dbid> where
# dbid is a number between 0 and 'databases' - 1, limited in [1, 8]
# databases : 1
databases : <DATABASES>
# default slot number each table in sharding mode
# default-slot-num : 1024
default-slot-num : <DEFAULT-SLOT-NUM>
# replication num defines how many followers in a single raft group, only [0, 1, 2, 3, 4] is valid
# replication-num : 0
replication-num : <REPLICATION-NUM>
# consensus level defines how many confirms does leader get, before commit this log to client,
#                 only [0, ...replicaiton-num] is valid
# consensus-level : 0
consensus-level : <CONSENSUS-LEVEL>
# Dump Prefix
# dump-prefix :
dump-prefix : <DUMP-PREFIX>
# daemonize  [yes | no]
#daemonize : yes
# Dump Path
# dump-path : ./dump/
dump-path : <DUMP-PATH>
# Expire-dump-days
# dump-expire : 0
dump-expire : <DUMP-EXPIRE>
# pidfile Path
pidfile : ./pika.pid
# Max Connection
# maxclients : 20000
maxclients : <MAXCLIENTS>
# the per file size of sst to compact, default is 20M
# target-file-size-base : 20971520
target-file-size-base : <TARGET-FILE-SIZE-BASE>
# Expire-logs-days
# expire-logs-days : 7
expire-logs-days : <EXPIRE-LOGS-DAYS>
# Expire-logs-nums
# expire-logs-nums : 10
expire-logs-nums : <EXPIRE-LOGS-NUMS>
# Root-connection-num
# root-connection-num : 2
root-connection-num : <ROOT-CONNECTION-NUM>
# Slowlog-write-errorlog
# slowlog-write-errorlog : no
slowlog-write-errorlog : <SLOWLOG-WRITE-ERRORLOG>
# Slowlog-log-slower-than
# slowlog-log-slower-than : 10000
slowlog-log-slower-than : <SLOWLOG-LOG-SLOWER-THAN>
# Slowlog-max-len
# slowlog-max-len : 128
slowlog-max-len : <SLOWLOG-MAX-LEN>
# Pika db sync path
# db-sync-path : ./dbsync/
db-sync-path : <DB-SYNC-PATH>
# db sync speed(MB) max is set to 1024MB, min is set to 0, and if below 0 or above 1024, the value will be adjust to 1024
# db-sync-speed : -1
db-sync-speed : <DB-SYNC-SPEED>
# The slave priority
# slave-priority : 100
slave-priority : <SLAVE-PRIORITY>
# network interface
#network-interface : eth1
# replication
#slaveof : master-ip:master-port

# CronTask, format 1: start-end/ratio, like 02-04/60, pika will check to schedule compaction between 2 to 4 o'clock everyday
#                   if the freesize/disksize > 60%.
#           format 2: week/start-end/ratio, like 3/02-04/60, pika will check to schedule compaction between 2 to 4 o'clock
#                   every wednesday, if the freesize/disksize > 60%.
#           NOTICE: if compact-interval is set, compact-cron will be mask and disable.
#
#compact-cron : 3/02-04/60

# Compact-interval, format: interval/ratio, like 6/60, pika will check to schedule compaction every 6 hours,
#                           if the freesize/disksize > 60%. NOTICE:compact-interval is prior than compact-cron;
#compact-interval :

# the size of flow control window while sync binlog between master and slave.Default is 9000 and the maximum is 90000.
# sync-window-size : 9000
sync-window-size : <SYNC-WINDOW-SIZE>
# max value of connection read buffer size: configurable value 67108864(64MB) or 268435456(256MB) or 536870912(512MB)
#                                           default value is 268435456(256MB)
#                                           NOTICE: master and slave should share exactly the same value
# max-conn-rbuf-size : 268435456
max-conn-rbuf-size : <MAX-CONN-RBUF-SIZE>


###################
## Critical Settings
###################
# write_binlog  [yes | no]
# write-binlog : yes
write-binlog : <WRITE-BINLOG>
# binlog file size: default is 100M,  limited in [1K, 2G]
# slave binlog file size must be the same with master's
# binlog-file-size : 104857600
binlog-file-size : <BINLOG-FILE-SIZE>
# Automatically triggers a small compaction according statistics
# Use the cache to store up to 'max-cache-statistic-keys' keys
# if 'max-cache-statistic-keys' set to '0', that means turn off the statistics function
# it also doesn't automatically trigger a small compact feature
# max-cache-statistic-keys : 0
max-cache-statistic-keys : <MAX-CACHE-STATISTIC-KEYS>
# When 'delete' or 'overwrite' a specific multi-data structure key 'small-compaction-threshold' times,
# a small compact is triggered automatically, default is 5000, limited in [1, 100000]
# small-compaction-threshold : 5000
small-compaction-threshold : <SMALL-COMPACTION-THRESHOLD>
# If the total size of all live memtables of all the DBs exceeds
# the limit, a flush will be triggered in the next DB to which the next write
# is issued.
# max-write-buffer-size : 10737418240
max-write-buffer-size : <MAX-WRITE-BUFFER-SIZE>
# The maximum number of write buffers that are built up in memory for one ColumnFamily in DB.
# The default and the minimum number is 2, so that when 1 write buffer
# is being flushed to storage, new writes can continue to the other write buffer.
# If max-write-buffer-num > 3, writing will be slowed down
# if we are writing to the last write buffer allowed.
# max-write-buffer-num : 2
max-write-buffer-num : <MAX-WRITE-BUFFER-NUM>
# Limit some command response size, like Scan, Keys*
# max-client-response-size : 1073741824
max-client-response-size : <MAX-CLIENT-RESPONSE-SIZE>
# Compression type supported [snappy, zlib, lz4, zstd]
# compression : snappy
compression : <COMPRESSION>
# max-background-flushes: default is 1, limited in [1, 4]
# max-background-flushes : 1
max-background-flushes : <MAX-BACKGROUND-FLUSHES>
# max-background-compactions: default is 2, limited in [1, 8]
# max-background-compactions : 2
max-background-compactions : <MAX-BACKGROUND-COMPACTIONS>
# maximum value of Rocksdb cached open file descriptors
# max-cache-files : 5000
max-cache-files : <MAX-CACHE-FILES>
# max_bytes_for_level_multiplier: default is 10, you can change it to 5
# max-bytes-for-level-multiplier : 10
max-bytes-for-level-multiplier : <MAX-BYTES-FOR-LEVEL-MULTIPLIER>
# BlockBasedTable block_size, default 4k
# block-size: 4096
# block LRU cache, default 8M, 0 to disable
# block-cache: 8388608
# num-shard-bits default -1, the number of bits from cache keys to be use as shard id.
# The cache will be sharded into 2^num_shard_bits shards.
# https://github.com/EighteenZi/rocksdb_wiki/blob/master/Block-Cache.md#lru-cache
# num-shard-bits: -1
# whether the block cache is shared among the RocksDB instances, default is per CF
# share-block-cache: no
# whether or not index and filter blocks is stored in block cache
# cache-index-and-filter-blocks: no
# pin_l0_filter_and_index_blocks_in_cache [yes | no]
# When `cache-index-and-filter-blocks` is enabled, `pin_l0_filter_and_index_blocks_in_cache` is suggested to be enabled
# pin_l0_filter_and_index_blocks_in_cache : no
# when set to yes, bloomfilter of the last level will not be built
# optimize-filters-for-hits: no
# https://github.com/facebook/rocksdb/wiki/Leveled-Compaction#levels-target-size
# level-compaction-dynamic-level-bytes: no
